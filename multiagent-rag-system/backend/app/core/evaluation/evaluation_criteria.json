{
  "version": "2.0",
  "last_updated": "2025-11-14",
  "description": "Multi-Model Ensemble 평가 지표 정의 - Gemini 2.5 Flash, Claude 3.5 Sonnet, GPT-4o 앙상블 평가",

  "evaluation_models": {
    "gemini": {
      "model_name": "gemini-2.5-flash",
      "temperature": 0.2,
      "max_tokens": 16384,
      "api_key_env": "GEMINI_API_KEY_1",
      "weight": 0.34
    },
    "claude": {
      "model_name": "claude-haiku-4-5-20251001",
      "temperature": 0.2,
      "max_tokens": 16384,
      "api_key_env": "EVALUATION_CLAUDE_API_KEY",
      "weight": 0.33
    },
    "gpt": {
      "model_name": "gpt-4o",
      "temperature": 0.2,
      "max_tokens": 16384,
      "api_key_env": "EVALUATION_OPENAI_API_KEY",
      "weight": 0.33
    }
  },

  "kpi_metrics": {
    "task_success_rate": {
      "name": "작업 성공률",
      "weight": 0.25,
      "description": "요구사항 충족도 및 작업 완료 여부",
      "measurement_type": "automatic",
      "evaluation_elements": {
        "report_generation": {
          "description": "보고서 생성 완료 여부",
          "weight": 0.30,
          "criteria": [
            "보고서가 정상적으로 생성되었는가?",
            "최소 길이 요구사항(1,000자 이상)을 충족하는가?",
            "치명적 오류 없이 완료되었는가?"
          ]
        },
        "required_sections": {
          "description": "필수 섹션 포함 여부",
          "weight": 0.40,
          "criteria": [
            "서론/개요가 포함되어 있는가?",
            "본문 분석 섹션이 포함되어 있는가?",
            "결론/요약이 포함되어 있는가?",
            "출처 목록이 포함되어 있는가?"
          ]
        },
        "requirement_fulfillment": {
          "description": "요구사항 항목 충족도",
          "weight": 0.30,
          "criteria": [
            "쿼리에서 요청한 모든 항목이 다뤄졌는가?",
            "분석/방안/전략 등 요구된 형식을 준수했는가?",
            "페르소나에 맞는 관점과 용어를 사용했는가?"
          ]
        }
      },
      "scoring_formula": "sum(element_weight * element_score) / total_weight * 10"
    },

    "output_quality": {
      "name": "품질 점수",
      "weight": 0.25,
      "description": "AI Judge 기반 보고서 품질 평가",
      "measurement_type": "ai_judge",
      "sub_metrics": {
        "factual_accuracy": {
          "name": "사실 정확도",
          "weight": 0.40,
          "description": "제시된 데이터, 통계, 사실 주장의 정확성",
          "evaluation_elements": {
            "data_accuracy": {
              "description": "수치 데이터의 정확성",
              "criteria": [
                "제시된 통계와 수치가 출처와 일치하는가?",
                "날짜, 시간, 금액 등이 정확한가?",
                "단위(kg, 원, % 등)가 올바르게 표기되었는가?"
              ]
            },
            "fact_verification": {
              "description": "사실 주장의 검증 가능성",
              "criteria": [
                "모든 주장에 적절한 출처가 인용되었는가?",
                "출처 없는 추측이나 가정이 명시되었는가?",
                "시간적 맥락(예: 2024년 기준)이 명확한가?"
              ]
            },
            "citation_accuracy": {
              "description": "인용의 정확성",
              "criteria": [
                "[SOURCE:N] 태그가 실제 출처 N과 일치하는가?",
                "인용된 내용이 출처에서 왜곡되지 않았는가?",
                "출처의 맥락이 올바르게 반영되었는가?"
              ]
            }
          }
        },
        "logical_coherence": {
          "name": "논리적 일관성",
          "weight": 0.30,
          "description": "보고서의 논리 구조와 흐름",
          "evaluation_elements": {
            "argument_structure": {
              "description": "논증 구조의 타당성",
              "criteria": [
                "주장과 근거가 논리적으로 연결되는가?",
                "인과관계가 명확하고 타당한가?",
                "반론에 대한 고려가 있는가?"
              ]
            },
            "flow_and_transition": {
              "description": "섹션 간 흐름과 전환",
              "criteria": [
                "섹션 간 연결이 자연스러운가?",
                "중복되거나 모순되는 내용이 없는가?",
                "전체적인 서사 구조가 명확한가?"
              ]
            },
            "conclusion_validity": {
              "description": "결론 도출의 타당성",
              "criteria": [
                "결론이 본문 내용에서 자연스럽게 도출되는가?",
                "과도한 일반화나 비약이 없는가?",
                "제언이 분석 결과와 부합하는가?"
              ]
            }
          }
        },
        "relevance": {
          "name": "요구사항 부합도",
          "weight": 0.30,
          "description": "원본 쿼리와의 일치도",
          "evaluation_elements": {
            "query_alignment": {
              "description": "쿼리 의도 파악 및 반영",
              "criteria": [
                "사용자가 요청한 주제를 정확히 다루는가?",
                "요청한 범위(시간, 지역, 대상 등)를 준수하는가?",
                "요청하지 않은 무관한 내용이 없는가?"
              ]
            },
            "format_compliance": {
              "description": "요청한 형식 준수",
              "criteria": [
                "보고서/분석/전략 등 요청한 형식으로 작성되었는가?",
                "페르소나별 관점(구매자, 연구원 등)이 반영되었는가?",
                "요청한 상세도 수준(개요 vs 심층분석)이 적절한가?"
              ]
            },
            "specificity": {
              "description": "구체성 및 실용성",
              "criteria": [
                "추상적 설명이 아닌 구체적 사례를 제공하는가?",
                "실행 가능한 제언이 포함되어 있는가?",
                "적절한 수준의 전문성을 유지하는가?"
              ]
            }
          }
        }
      },
      "scoring_formula": "(factual_accuracy * 0.40) + (logical_coherence * 0.30) + (relevance * 0.30)"
    },

    "completeness": {
      "name": "완성도",
      "weight": 0.20,
      "description": "보고서 구조 및 내용의 완성도",
      "measurement_type": "automatic",
      "evaluation_elements": {
        "section_completeness": {
          "description": "섹션 완성도",
          "weight": 0.60,
          "criteria": [
            "예상된 모든 마크다운 헤더(#, ##, ###)가 존재하는가?",
            "각 섹션이 완전한 문장으로 종료되는가?",
            "미완성 표시(..., 문장 중간 끊김)가 없는가?"
          ]
        },
        "schema_completeness": {
          "description": "스키마 완성도",
          "weight": 0.40,
          "criteria": [
            "제목(# Heading)이 있는가?",
            "서론/개요가 있는가?",
            "본문 섹션(## Heading)들이 있는가?",
            "결론/요약이 있는가?",
            "출처 목록이 있는가?"
          ]
        }
      },
      "scoring_formula": "(section_completeness * 0.60) + (schema_completeness * 0.40)"
    },

    "hallucination": {
      "name": "환각 점수 (역점수)",
      "weight": 0.15,
      "description": "출처에 없는 정보, 과장, 왜곡 탐지",
      "measurement_type": "ai_judge",
      "hallucination_types": {
        "citation_inaccuracy": {
          "name": "인용 부정확성",
          "severity": 2,
          "description": "[SOURCE:N] 태그가 실제 출처와 불일치",
          "detection_criteria": [
            "[SOURCE:N] 태그가 가리키는 출처 번호가 실제 출처 목록에 없음",
            "인용된 내용이 해당 출처에 존재하지 않음",
            "출처 내용을 왜곡하거나 과장함"
          ]
        },
        "unfounded_claims": {
          "name": "근거 없는 주장",
          "severity": 2,
          "description": "출처에 없는 정보를 사실처럼 제시",
          "detection_criteria": [
            "출처에 없는 통계나 수치를 마치 확인된 것처럼 제시",
            "출처에서 언급되지 않은 사건이나 사실을 주장",
            "추론이나 추측을 사실로 단정"
          ]
        },
        "exaggeration": {
          "name": "과장 또는 왜곡",
          "severity": 1,
          "description": "사실을 과장하거나 왜곡하여 표현",
          "detection_criteria": [
            "출처의 표현을 더 강하게 과장 (예: '증가' → '급증')",
            "부분적 사실을 전체인 것처럼 일반화",
            "맥락을 무시하고 일부만 선택적으로 인용"
          ]
        }
      },
      "scoring_formula": "max(0, 10 - sum(hallucination_count * severity))"
    },

    "efficiency": {
      "name": "효율성 점수",
      "weight": 0.10,
      "description": "실행 시간 및 리소스 효율성",
      "measurement_type": "automatic",
      "evaluation_elements": {
        "execution_time": {
          "description": "보고서 생성 소요 시간",
          "weight": 0.70,
          "scoring_ranges": [
            {"max_seconds": 60, "score": 10.0},
            {"max_seconds": 90, "score": 8.0},
            {"max_seconds": 120, "score": 6.5},
            {"max_seconds": 180, "score": 5.0},
            {"min_seconds": 180, "score": "max(4.0, 6.5 - (time-120)/60)"}
          ]
        },
        "api_efficiency": {
          "description": "API 호출 효율성",
          "weight": 0.15,
          "scoring_formula": "max(0, 10 - (api_calls - 5) * 0.5)"
        },
        "token_efficiency": {
          "description": "토큰 사용 효율성",
          "weight": 0.15,
          "scoring_formula": "max(0, 10 - (total_tokens - 5000) / 1000)"
        }
      },
      "scoring_formula": "sum(element_weight * element_score)"
    },

    "source_quality": {
      "name": "출처 품질",
      "weight": 0.05,
      "description": "출처의 신뢰도 및 다양성",
      "measurement_type": "automatic",
      "evaluation_elements": {
        "credibility": {
          "description": "출처 신뢰도 평균",
          "weight": 0.50,
          "credibility_levels": {
            "peer_reviewed": {"score": 1.0, "sources": ["PubMed", "arXiv", "학술지"]},
            "government": {"score": 0.9, "sources": ["농림부", "식약처", "통계청"]},
            "industry_report": {"score": 0.8, "sources": ["시장조사", "산업보고서"]},
            "news": {"score": 0.6, "sources": ["뉴스", "언론"]},
            "blog": {"score": 0.4, "sources": ["블로그", "커뮤니티"]}
          }
        },
        "diversity": {
          "description": "출처 다양성",
          "weight": 0.50,
          "criteria": [
            "사용된 검색 도구의 수 (Vector DB, Graph DB, RDB, Web, PubMed 등)",
            "출처 유형의 다양성 (학술, 정부, 산업, 뉴스 등)",
            "시간적 범위 (최신 자료와 과거 자료의 균형)"
          ],
          "scoring_formula": "len(unique_tools) / total_available_tools"
        }
      },
      "scoring_formula": "((avg_credibility + diversity) / 2) * 10"
    },

    "content_metrics": {
      "name": "콘텐츠 메트릭",
      "weight": 0.0,
      "description": "참고용 통계 (점수 미반영)",
      "measurement_type": "automatic",
      "metrics": {
        "word_count": {"description": "총 단어 수", "unit": "words"},
        "section_count": {"description": "섹션 수", "unit": "sections"},
        "chart_count": {"description": "차트 수", "unit": "charts"},
        "citation_count": {"description": "인용 수", "unit": "citations"},
        "avg_sentence_length": {"description": "평균 문장 길이", "unit": "words"}
      }
    }
  },

  "evaluation_requirements": {
    "description": "보고서가 충족해야 하는 필수 요구사항",
    "mandatory_requirements": {
      "content": [
        "사용자가 요청한 주제를 다룰 것",
        "요청한 시간 범위 내의 정보를 제공할 것",
        "요청한 형식(보고서/분석/전략 등)으로 작성할 것",
        "페르소나에 맞는 관점과 용어를 사용할 것"
      ],
      "structure": [
        "서론 또는 개요 포함",
        "본문 분석 섹션 포함 (2개 이상)",
        "결론 또는 요약 포함",
        "출처 목록 제공"
      ],
      "quality": [
        "모든 주장에 출처 인용 ([SOURCE:N] 형식)",
        "출처 없는 추측이나 가정은 명시적으로 표시",
        "완전한 문장으로 작성 (미완성 금지)",
        "논리적 일관성 유지 (모순 없음)"
      ]
    },
    "optional_requirements": {
      "enhancement": [
        "데이터 시각화 (차트, 그래프)",
        "구체적 사례 및 예시",
        "실행 가능한 제언",
        "다양한 관점 제시"
      ]
    }
  },

  "ai_judge_prompts": {
    "factual_accuracy_prompt": "당신은 **데이터 검증 전문가**입니다. 보고서의 사실 정확도를 단계별로 평가하세요.\n\n## 채점 기준표 (Rubric)\n\n| 점수 범위 | 데이터 정확성 | 출처 인용 | 시간적 맥락 |\n|---------|-------------|---------|----------|\n| 9.0-10.0 | 모든 수치가 출처와 정확히 일치 | 모든 사실 주장에 출처 인용 | 날짜/기간이 명확하고 정확 |\n| 7.0-8.9 | 대부분 정확하나 경미한 오류 1-2개 | 주요 주장에는 출처 있음 | 대체로 명확함 |\n| 5.0-6.9 | 중요한 수치에 오류 있음 | 절반 정도만 출처 인용 | 일부 모호함 |\n| 3.0-4.9 | 다수의 수치 오류 또는 왜곡 | 출처 인용 부족 | 시간 맥락 불분명 |\n| 0.0-2.9 | 대부분의 수치가 틀리거나 조작됨 | 출처 거의 없음 | 시간 정보 없거나 틀림 |\n\n## 평가 예시 (Few-Shot Examples)\n\n### 예시 1: 우수한 경우 (9.5점)\n**보고서:** \"2024년 글로벌 대체육 시장은 50억 달러 규모로, 전년 대비 15% 성장했습니다. [SOURCE:0] 주요 성장 동력은 MZ세대의 건강 의식 증가입니다. [SOURCE:1]\"\n**출처 0:** \"2024년 글로벌 대체육 시장 규모는 50억 달러이며, 2023년 43.5억 달러 대비 15% 증가했습니다.\"\n**출처 1:** \"소비자 조사 결과, MZ세대(18-39세)의 72%가 건강을 이유로 대체육을 구매한다고 응답했습니다.\"\n**평가:** {{\n  \"score\": 9.5,\n  \"reasoning\": \"수치(50억 달러, 15%)가 출처와 정확히 일치. 모든 주장에 적절한 출처 인용. 시간 범위(2024년, 전년 대비) 명확.\",\n  \"issues\": []\n}}\n\n### 예시 2: 보통인 경우 (6.5점)\n**보고서:** \"대체육 시장은 급성장하고 있으며, 향후 5년간 연평균 약 25% 성장할 것으로 예상됩니다.\"\n**출처:** (관련 출처 없음)\n**평가:** {{\n  \"score\": 6.5,\n  \"reasoning\": \"'급성장'은 모호한 표현. 구체적 수치(25%)를 제시했으나 출처 인용 없음. 예측 수치의 근거 불명확.\",\n  \"issues\": [\"출처 미인용\", \"예측 수치의 근거 부족\", \"모호한 표현('급성장')\"]\n}}\n\n### 예시 3: 부적절한 경우 (3.0점)\n**보고서:** \"2024년 대체육 시장은 100억 달러를 돌파했습니다. [SOURCE:0]\"\n**출처 0:** \"2024년 글로벌 대체육 시장 규모는 50억 달러입니다.\"\n**평가:** {{\n  \"score\": 3.0,\n  \"reasoning\": \"보고서의 수치(100억)가 출처(50억)와 명백히 불일치. 실제의 2배로 과장. 출처 왜곡.\",\n  \"issues\": [\"수치 왜곡 - 실제의 2배로 과장\", \"출처 내용과 불일치\"]\n}}\n\n---\n\n## 평가 절차 (Chain-of-Thought)\n\n**Step 1: 출처 매핑 확인**\n- 보고서의 모든 [SOURCE:N] 태그 식별\n- 각 태그가 실제 출처 목록에 존재하는지 확인\n\n**Step 2: 수치 데이터 검증**\n- 보고서의 모든 숫자(통계, 금액, 비율, 날짜 등) 추출\n- 각 수치를 해당 출처와 비교\n- 일치/불일치 여부 판단\n\n**Step 3: 사실 주장 검증**\n- [SOURCE:N] 주변의 주장 내용 추출\n- 해당 출처에서 실제로 그런 내용을 언급했는지 확인\n- 왜곡이나 과장 여부 판단\n\n**Step 4: 시간적 맥락 확인**\n- 날짜, 기간, 시점이 명시되어 있는가?\n- 명시된 시간 정보가 정확한가?\n\n**Step 5: 종합 평가**\n- 위 4단계 결과를 종합\n- 채점 기준표에 따라 점수 부여\n- 발견된 문제점 나열\n\n---\n\n## 실제 평가 대상\n\n보고서:\n{report}\n\n출처 목록:\n{sources}\n\n**위의 5단계 절차를 따라 평가하고, 다음 JSON 형식으로 반환하세요:**\n{{\n  \"score\": 0-10,\n  \"reasoning\": \"Step 1~5의 평가 과정을 상세히 서술. 어떤 수치를 검증했는지, 출처와 일치했는지 구체적으로 명시.\",\n  \"issues\": [\"발견된 문제점들\"]\n}}",

    "logical_coherence_prompt": "당신은 **15년 경력의 학술 논문 심사위원**입니다. 연간 200편 이상의 논문을 평가하며, 특히 **논리 구조와 논증 타당성** 검증에 전문성이 있습니다.\n\n## 당신의 평가 원칙\n- 모든 주장은 명확한 근거로 뒷받침되어야 함\n- 인과관계와 상관관계를 명확히 구분해야 함\n- 논리적 비약이나 과도한 일반화는 경계해야 함\n- 섹션 간 연결이 자연스럽고 일관성이 있어야 함\n\n## 채점 기준표 (Rubric)\n\n| 점수 범위 | 논증 구조 | 섹션 흐름 | 결론 타당성 |\n|---------|---------|---------|----------|\n| 9.0-10.0 | 주장-근거 완벽히 연결, 논리적 비약 없음 | 섹션 간 자연스러운 전환, 중복/모순 없음 | 결론이 본문에서 명확히 도출됨 |\n| 7.0-8.9 | 대체로 논리적이나 경미한 비약 1-2개 | 대부분 자연스러우나 일부 어색함 | 결론이 타당하나 일부 근거 부족 |\n| 5.0-6.9 | 논리적 연결 약함, 여러 비약 존재 | 섹션 간 단절감, 일부 중복 | 결론 도출 과정 불분명 |\n| 3.0-4.9 | 주장과 근거 불일치, 논리 오류 다수 | 흐름 파악 어려움, 모순 존재 | 결론이 본문과 무관하거나 비약 |\n| 0.0-2.9 | 논리 구조 부재 | 섹션 간 관련성 없음 | 결론 없거나 완전히 부적절 |\n\n## 평가 절차 (Chain-of-Thought)\n\n**Step 1: 전체 구조 파악**\n- 서론-본론-결론 구조가 명확한가?\n- 각 섹션의 역할이 분명한가?\n\n**Step 2: 논증 구조 분석**\n- 각 주장(Claim)을 식별\n- 각 주장을 뒷받침하는 근거(Evidence) 확인\n- 주장과 근거의 논리적 연결 평가\n- 논리적 오류(인과관계 혼동, 과도한 일반화 등) 탐지\n\n**Step 3: 흐름과 전환 평가**\n- 섹션 간 전환이 자연스러운가?\n- 중복되는 내용이 있는가?\n- 서로 모순되는 주장이 있는가?\n\n**Step 4: 결론 타당성 검증**\n- 결론이 본문 내용에서 논리적으로 도출되는가?\n- 과도한 일반화나 비약이 있는가?\n- 제언이 분석 결과와 부합하는가?\n\n**Step 5: 종합 평가**\n- 채점 기준표에 따라 점수 부여\n- 강점과 약점 정리\n\n---\n\n## 실제 평가 대상\n\n보고서:\n{report}\n\n**위의 5단계 절차를 따라 평가하고, 다음 JSON 형식으로 반환하세요:**\n{{\n  \"score\": 0-10,\n  \"reasoning\": \"Step 1~5의 평가 과정을 상세히 서술. 어떤 논리적 오류를 발견했는지, 섹션 간 흐름이 어떤지 구체적으로 명시.\",\n  \"strengths\": [\"발견된 강점들\"],\n  \"weaknesses\": [\"발견된 약점들\"]\n}}",

    "relevance_prompt": "보고서가 원본 쿼리의 요구사항을 얼마나 잘 충족하는지 평가하세요.\n\n## 채점 기준표 (Rubric)\n\n| 점수 범위 | 주제 정확도 | 형식 준수 | 구체성 |\n|---------|----------|---------|-------|\n| 9.0-10.0 | 요청한 모든 주제 완벽 다룸 | 요청 형식 완전 준수 | 구체적 사례+실행안 풍부 |\n| 7.0-8.9 | 주요 주제 다룸, 일부 누락 | 대체로 준수 | 대체로 구체적 |\n| 5.0-6.9 | 주제 일부만 다룸 | 형식 부분 불일치 | 추상적 설명 위주 |\n| 3.0-4.9 | 주제 크게 벗어남 | 형식 미준수 | 구체성 없음 |\n| 0.0-2.9 | 완전히 무관한 내용 | 형식 완전 불일치 | 실용성 없음 |\n\n## 대조 예시 (Contrastive Examples)\n\n### 예시 1: 우수한 보고서 (9.0점)\n**쿼리:** \"2024년 대체육 시장 동향과 소비자 선호도를 분석해주세요\"\n**보고서 특징:**\n- 2024년 시장 규모, 성장률 등 '동향' 구체적으로 제시\n- 소비자 선호도 조사 결과 포함\n- 시장 분석 형식으로 작성\n- 구체적 수치와 사례 풍부\n\n### 예시 2: 부적절한 보고서 (4.5점)\n**쿼리:** \"2024년 대체육 시장 동향과 소비자 선호도를 분석해주세요\"\n**보고서 특징:**\n- 대체육의 역사와 제조 공정 설명 (요청하지 않음)\n- 2024년 데이터 없이 2020년 데이터 사용\n- 소비자 선호도 언급 없음\n- 추상적이고 일반적인 설명만 나열\n\n---\n\n## 평가 절차 (Chain-of-Thought)\n\n**Step 1: 쿼리 분석**\n- 사용자가 요청한 핵심 주제 추출 (예: '2024년 대체육 시장 동향', '소비자 선호도')\n- 시간 범위 확인 (예: 2024년)\n- 요청 형식 확인 (예: 분석, 보고서, 전략)\n\n**Step 2: 보고서 내용 매칭**\n- 각 요청 주제가 보고서에 포함되었는가?\n- 요청한 시간 범위 내의 정보인가?\n- 요청하지 않은 무관한 내용은 없는가?\n\n**Step 3: 형식 준수 확인**\n- 요청한 형식(보고서/분석/전략)으로 작성되었는가?\n- 페르소나(구매자, 연구원 등) 관점이 반영되었는가?\n\n**Step 4: 구체성 평가**\n- 구체적 사례, 수치, 데이터가 포함되었는가?\n- 실행 가능한 제언이 있는가?\n\n**Step 5: 종합 평가**\n- 채점 기준표에 따라 점수 부여\n- 충족/누락된 요구사항 정리\n\n---\n\n## 실제 평가 대상\n\n원본 쿼리:\n{query}\n\n보고서:\n{report}\n\n**위의 5단계 절차를 따라 평가하고, 다음 JSON 형식으로 반환하세요:**\n{{\n  \"score\": 0-10,\n  \"reasoning\": \"Step 1~5의 평가 과정을 상세히 서술. 쿼리의 어떤 요구사항이 충족/누락되었는지 구체적으로 명시.\",\n  \"fulfilled_requirements\": [\"충족된 요구사항들\"],\n  \"missing_requirements\": [\"누락된 요구사항들\"]\n}}",

    "hallucination_prompt": "당신은 **환각 탐지 전문가**입니다. 보고서에서 출처에 없는 정보, 과장, 왜곡을 엄격하게 탐지하세요.\n\n## 환각 유형 및 심각도\n\n1. **인용 부정확성 (Severity: 2)**: [SOURCE:N] 태그가 실제 출처와 불일치\n2. **근거 없는 주장 (Severity: 2)**: 출처에 없는 정보를 사실처럼 제시\n3. **과장/왜곡 (Severity: 1)**: 사실을 과장하거나 왜곡하여 표현\n\n## 탐지 예시 (Few-Shot Examples)\n\n### 예시 1: 인용 부정확성\n**보고서:** \"2024년 시장 규모는 100억 달러입니다. [SOURCE:0]\"\n**출처 0:** \"2024년 시장 규모는 50억 달러로 추정됩니다.\"\n**탐지 결과:**\n{{\n  \"type\": \"citation_inaccuracy\",\n  \"location\": \"시장 규모 언급 부분\",\n  \"description\": \"보고서는 100억 달러라고 했으나, 출처 0은 50억 달러라고 명시. 2배 과장.\",\n  \"severity\": 2\n}}\n\n### 예시 2: 근거 없는 주장\n**보고서:** \"전문가들은 향후 5년간 연평균 30% 성장할 것으로 전망합니다.\"\n**출처:** (관련 내용 없음)\n**탐지 결과:**\n{{\n  \"type\": \"unfounded_claims\",\n  \"location\": \"성장 전망 부분\",\n  \"description\": \"30% 성장 전망을 언급했으나 어떤 출처에도 이 수치가 없음. 출처 없는 예측.\",\n  \"severity\": 2\n}}\n\n### 예시 3: 과장/왜곡\n**보고서:** \"시장이 폭발적으로 성장하고 있습니다.\"\n**출처:** \"시장은 꾸준히 성장하고 있습니다.\"\n**탐지 결과:**\n{{\n  \"type\": \"exaggeration\",\n  \"location\": \"시장 성장 서술 부분\",\n  \"description\": \"출처는 '꾸준히'라고 했으나 보고서는 '폭발적으로'로 과장. 표현 강도 증폭.\",\n  \"severity\": 1\n}}\n\n---\n\n## 탐지 절차 (Chain-of-Thought)\n\n**Step 1: 출처 매핑 검증**\n- 보고서의 모든 [SOURCE:N] 태그 식별\n- 각 N이 실제 출처 목록에 존재하는지 확인\n- 존재하지 않는 번호 사용 시 → 인용 부정확성\n\n**Step 2: 인용 내용 검증**\n- 각 [SOURCE:N] 주변의 주장 추출\n- 해당 출처 N의 실제 내용과 비교\n- 불일치 시 → 인용 부정확성 또는 과장/왜곡\n\n**Step 3: 출처 없는 주장 탐지**\n- [SOURCE:N] 태그가 없는 사실 주장들 식별\n- 각 주장이 어떤 출처에서든 지지되는지 확인\n- 어디에도 없는 정보 → 근거 없는 주장\n\n**Step 4: 수치 검증**\n- 보고서의 모든 숫자(통계, 금액, 비율 등) 추출\n- 각 수치가 출처와 정확히 일치하는지 확인\n- 불일치 시 → 인용 부정확성\n\n**Step 5: 표현 강도 비교**\n- 출처의 표현(예: '증가')과 보고서의 표현(예: '급증', '폭발적') 비교\n- 과도하게 강화된 표현 → 과장/왜곡\n\n**Step 6: 종합 판정**\n- 발견된 환각 유형별로 정리\n- 환각 건수 계산\n- 인용 정확도 = (정확한 인용 수 / 전체 인용 수)\n\n---\n\n## 엄격한 검증 기준\n\n- **의심스러우면 환각으로 판정**: 출처에서 명확히 확인되지 않으면 환각\n- **추론과 사실을 구분**: \"~로 보입니다\", \"~것으로 추정됩니다\" 등은 괜찮지만, 단정적 표현(\"~입니다\")은 출처 필수\n- **수치는 정확히 일치해야 함**: \"약 50억\"과 \"50억\"도 엄밀히는 다름\n- **맥락 왜곡도 환각**: 출처의 일부만 선택적으로 인용하여 의미를 왜곡한 경우\n\n---\n\n## 실제 평가 대상\n\n보고서:\n{report}\n\n전체 출처 내용:\n{sources}\n\n**위의 6단계 절차를 따라 엄격히 검증하고, 다음 JSON 형식으로 반환하세요:**\n{{\n  \"hallucination_count\": 0,\n  \"hallucinations\": [\n    {{\n      \"type\": \"citation_inaccuracy | unfounded_claims | exaggeration\",\n      \"location\": \"보고서 내 위치\",\n      \"description\": \"환각 내용 상세 설명\",\n      \"severity\": 1-2\n    }}\n  ],\n  \"citation_accuracy\": 0.0-1.0,\n  \"unverified_claims\": [\"검증되지 않은 주장들\"],\n  \"contradictions\": [\"출처와 모순되는 내용들\"],\n  \"confidence_score\": 0.0-1.0\n}}"
  },

  "ensemble_config": {
    "aggregation_method": "weighted_average",
    "description": "3개 모델의 평가 점수를 가중 평균으로 집계",
    "consensus_threshold": 0.7,
    "disagreement_handling": {
      "method": "median",
      "description": "모델 간 점수 차이가 3점 이상일 경우 중앙값 사용"
    },
    "confidence_weighting": {
      "enabled": true,
      "description": "각 모델의 reasoning 길이와 구체성을 기반으로 신뢰도 가중치 조정"
    }
  },

  "grading_scale": {
    "A+": {"min": 9.5, "max": 10.0, "description": "탁월함"},
    "A": {"min": 9.0, "max": 9.4, "description": "우수함"},
    "B+": {"min": 8.5, "max": 8.9, "description": "양호함"},
    "B": {"min": 8.0, "max": 8.4, "description": "보통"},
    "C+": {"min": 7.5, "max": 7.9, "description": "미흡"},
    "C": {"min": 7.0, "max": 7.4, "description": "부족"},
    "D": {"min": 6.0, "max": 6.9, "description": "불량"},
    "F": {"min": 0.0, "max": 5.9, "description": "실패"}
  }
}
