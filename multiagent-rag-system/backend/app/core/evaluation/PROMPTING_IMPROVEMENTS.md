# AI Judge 평가 프롬프트 고도화 (2025-11-20)

## 개선 목적
AI Judge의 평가 일관성, 정확도, 신뢰도를 향상시키기 위해 최신 프롬프팅 기법을 적용

## 적용된 프롬프팅 기법

### 1. Few-Shot Learning (예시 기반 학습)
- **목적**: 모델이 평가 기준을 더 명확하게 이해하도록 함
- **적용 위치**: 모든 평가 프롬프트
- **방법**: 각 평가 항목별로 3가지 예시 제공
  - 우수한 경우 (9.0-10.0점)
  - 보통인 경우 (5.0-7.0점)
  - 부적절한 경우 (0.0-4.0점)

**예시 (사실 정확도 평가):**
```
### 예시 1: 우수한 경우 (9.5점)
보고서: "2024년 글로벌 대체육 시장은 50억 달러 규모로, 전년 대비 15% 성장했습니다. [SOURCE:0]"
출처 0: "2024년 글로벌 대체육 시장 규모는 50억 달러이며, 2023년 43.5억 달러 대비 15% 증가했습니다."
평가: { "score": 9.5, "reasoning": "수치가 출처와 정확히 일치..." }
```

### 2. Chain-of-Thought (CoT) - 단계별 추론
- **목적**: 모델이 단계별로 사고하며 더 신중하게 평가하도록 유도
- **적용 위치**: 모든 평가 프롬프트
- **방법**: 5-6단계의 명확한 평가 절차 제시

**예시 (환각 탐지):**
```
Step 1: 출처 매핑 검증
Step 2: 인용 내용 검증
Step 3: 출처 없는 주장 탐지
Step 4: 수치 검증
Step 5: 표현 강도 비교
Step 6: 종합 판정
```

### 3. Rubric-Based Evaluation (채점 기준표)
- **목적**: 일관성 있는 채점 기준 제공
- **적용 위치**: 모든 평가 프롬프트
- **방법**: 점수 범위별 구체적인 평가 기준을 표 형식으로 제시

**예시 (사실 정확도):**
| 점수 범위 | 데이터 정확성 | 출처 인용 | 시간적 맥락 |
|---------|-------------|---------|----------|
| 9.0-10.0 | 모든 수치가 출처와 정확히 일치 | 모든 사실 주장에 출처 인용 | 날짜/기간이 명확하고 정확 |
| 7.0-8.9 | 대부분 정확하나 경미한 오류 1-2개 | 주요 주장에는 출처 있음 | 대체로 명확함 |
| ... | ... | ... | ... |

### 4. Role-Based Prompting (역할 부여)
- **목적**: 전문가 페르소나를 부여하여 평가 품질 향상
- **적용 위치**: 논리적 일관성, 환각 탐지
- **방법**: 구체적인 경력과 전문성을 명시

**예시:**
```
당신은 15년 경력의 학술 논문 심사위원입니다.
연간 200편 이상의 논문을 평가하며, 특히 논리 구조와 논증 타당성 검증에 전문성이 있습니다.

당신의 평가 원칙:
- 모든 주장은 명확한 근거로 뒷받침되어야 함
- 인과관계와 상관관계를 명확히 구분해야 함
...
```

### 5. Contrastive Prompting (대조적 예시)
- **목적**: 좋은 보고서와 나쁜 보고서의 차이를 명확히 함
- **적용 위치**: 요구사항 부합도 평가
- **방법**: 동일한 쿼리에 대한 우수/부적절 사례 대조

**예시:**
```
## 예시 1: 우수한 보고서 (9.0점)
특징: 2024년 시장 규모, 성장률 등 '동향' 구체적으로 제시...

## 예시 2: 부적절한 보고서 (4.5점)
특징: 대체육의 역사와 제조 공정 설명 (요청하지 않음)...
```

## 평가 항목별 적용 기법

### 1. 사실 정확도 (factual_accuracy_prompt)
- Few-Shot Learning (3가지 예시)
- Chain-of-Thought (5단계 절차)
- Rubric-Based Evaluation
- Role-Based ("데이터 검증 전문가")

**주요 개선점:**
- 수치 데이터 검증 절차 명확화
- 출처 매핑 확인 단계 추가
- 시간적 맥락 평가 강화

### 2. 논리적 일관성 (logical_coherence_prompt)
- Role-Based ("15년 경력 학술 논문 심사위원")
- Chain-of-Thought (5단계 절차)
- Rubric-Based Evaluation
- 평가 원칙 명시

**주요 개선점:**
- 논리적 오류 탐지 체계화 (인과관계 혼동, 과도한 일반화 등)
- 섹션 간 흐름 평가 강화
- 주장-근거 연결성 검증

### 3. 요구사항 부합도 (relevance_prompt)
- Few-Shot Learning (대조적 예시)
- Chain-of-Thought (5단계 절차)
- Rubric-Based Evaluation
- Contrastive Prompting (우수/부적절 대조)

**주요 개선점:**
- 쿼리 분석 절차 체계화
- 시간 범위 준수 여부 명확히 평가
- 무관한 내용 포함 여부 탐지

### 4. 환각 탐지 (hallucination_prompt)
- Few-Shot Learning (3가지 환각 유형별 예시)
- Chain-of-Thought (6단계 절차)
- Role-Based ("환각 탐지 전문가")
- 엄격한 검증 기준 명시

**주요 개선점:**
- 환각 유형별 구체적 예시 제공
- 6단계 검증 절차로 세밀한 탐지
- 엄격한 검증 기준 명시 ("의심스러우면 환각으로 판정")
- 추가 필드 요청: `unverified_claims`, `contradictions`, `confidence_score`

## 기대 효과

### 1. 평가 일관성 향상
- **Before**: 동일한 보고서에 대해 모델별로 점수 편차 큼 (3점 이상 차이 빈번)
- **After**: Few-Shot과 Rubric으로 평가 기준 통일, 모델 간 합의도 향상 예상

### 2. 평가 정확도 향상
- **Before**: 모호한 기준으로 인한 부정확한 평가
- **After**: CoT와 단계별 절차로 체계적 평가, 오류 감소 예상

### 3. 평가 신뢰도 향상
- **Before**: 평가 근거가 추상적
- **After**: Role-Based와 CoT로 구체적이고 상세한 reasoning 제공

### 4. 환각 탐지 정확도 향상
- **Before**: 환각을 놓치거나 과도하게 탐지
- **After**: 6단계 검증 절차와 구체적 예시로 정밀 탐지

## 성능 검증 계획

1. **기존 벤치마크 재평가**
   - 15개 벤치마크 쿼리에 대해 새로운 프롬프트로 재평가
   - 기존 결과와 비교 분석

2. **평가 지표**
   - 모델 간 점수 편차 (표준편차)
   - 환각 탐지 정밀도/재현율
   - Reasoning 구체성 (문자 수, 구체적 증거 포함 여부)

3. **A/B 테스트**
   - 동일 보고서에 대해 구 프롬프트 vs 신 프롬프트 비교
   - 전문가 평가와의 일치도 측정

## 향후 개선 방향

1. **Self-Consistency 적용**
   - 동일 평가를 3-5회 반복 후 다수결/중앙값 사용
   - 평가 신뢰도 더욱 향상

2. **Metacognitive Prompting**
   - 모델이 자신의 평가 확신도를 명시하도록 요청
   - 불확실한 평가 케이스 식별

3. **동적 Few-Shot 선택**
   - 평가 대상 보고서와 유사한 예시를 동적으로 선택
   - RAG 기반 Few-Shot 예시 검색

4. **프롬프트 최적화 자동화**
   - DSPy 등의 프롬프트 최적화 프레임워크 적용
   - 실제 평가 데이터 기반 프롬프트 자동 튜닝

## 참고 자료

- **Few-Shot Learning**: Brown et al., "Language Models are Few-Shot Learners" (2020)
- **Chain-of-Thought**: Wei et al., "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" (2022)
- **Rubric-Based Evaluation**: Anthropic, "Constitutional AI" (2022)
- **Role-Based Prompting**: OpenAI, "Best Practices for Prompt Engineering" (2023)

## 변경 이력

- **2025-11-20**: 초기 프롬프트 고도화 완료
  - 4개 평가 프롬프트에 Few-Shot + CoT + Rubric + Role-Based 적용
  - evaluation_criteria.json 업데이트
